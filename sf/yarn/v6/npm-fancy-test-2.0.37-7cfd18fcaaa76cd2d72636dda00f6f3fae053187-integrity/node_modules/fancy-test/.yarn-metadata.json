{
  "manifest": {
    "name": "fancy-test",
    "description": "extendable utilities for testing",
    "version": "2.0.37",
    "author": {
      "name": "Salesforce"
    },
    "bugs": {
      "url": "https://github.com/oclif/fancy-test/issues"
    },
    "dependencies": {
      "@types/chai": "*",
      "@types/lodash": "*",
      "@types/node": "*",
      "@types/sinon": "*",
      "lodash": "^4.17.13",
      "mock-stdin": "^1.0.0",
      "nock": "^13.3.3",
      "stdout-stderr": "^0.1.9"
    },
    "devDependencies": {
      "@types/mocha": "*",
      "chai": "^4.3.8",
      "chalk": "^4.1.0",
      "eslint": "^7.3.1",
      "eslint-config-oclif": "^3.1.0",
      "eslint-config-oclif-typescript": "^0.2.0",
      "http-call": "^5.2.3",
      "markdown-toc": "^1.2.0",
      "mocha": "^5.2.0",
      "sinon": "^9.0.2",
      "ts-node": "^9.0.0",
      "tslib": "^2.6.2",
      "typescript": "4.4.3"
    },
    "engines": {
      "node": ">=12.0.0"
    },
    "files": [
      "/lib"
    ],
    "homepage": "https://github.com/oclif/fancy-test",
    "keywords": [
      "mocha"
    ],
    "license": "MIT",
    "main": "lib/index.js",
    "repository": {
      "type": "git",
      "url": "https://github.com/oclif/fancy-test.git"
    },
    "scripts": {
      "build": "rm -rf lib && tsc",
      "lint": "eslint . --ext .ts --config .eslintrc",
      "posttest": "yarn lint",
      "prepublishOnly": "yarn run build",
      "test": "mocha --forbid-only \"test/**/*.test.ts\"",
      "version": "markdown-toc -i README.md && git add README.md",
      "pretest": "yarn build --noEmit && tsc -p test --noEmit"
    },
    "types": "lib/index.d.ts",
    "_registry": "npm",
    "_loc": "C:\\Users\\csmku\\AppData\\Local\\sf\\yarn\\v6\\npm-fancy-test-2.0.37-7cfd18fcaaa76cd2d72636dda00f6f3fae053187-integrity\\node_modules\\fancy-test\\package.json",
    "readmeFilename": "README.md",
    "readme": "fancy-test\n===========\n\nextendable utilities for testing\n\n[![Version](https://img.shields.io/npm/v/fancy-test.svg)](https://npmjs.org/package/fancy-test)\n[![CircleCI](https://circleci.com/gh/jdxcode/fancy-test/tree/main.svg?style=svg)](https://circleci.com/gh/jdxcode/fancy-test/tree/main)\n[![Known Vulnerabilities](https://snyk.io/test/npm/fancy-test/badge.svg)](https://snyk.io/test/npm/fancy-test)\n[![Downloads/week](https://img.shields.io/npm/dw/fancy-test.svg)](https://npmjs.org/package/fancy-test)\n[![License](https://img.shields.io/npm/l/fancy-test.svg)](https://github.com/jdxcode/fancy-test/blob/main/package.json)\n\n<!-- toc -->\n\n- [fancy-test](#fancy-test)\n- [Why](#why)\n- [Usage](#usage)\n  - [Stub](#stub)\n  - [Catch](#catch)\n  - [Finally](#finally)\n  - [Nock](#nock)\n  - [Environment Variables](#environment-variables)\n  - [Do](#do)\n  - [Add](#add)\n  - [Stdin Mocking](#stdin-mocking)\n  - [Stdout/Stderr Mocking](#stdoutstderr-mocking)\n  - [Done](#done)\n  - [Retries](#retries)\n  - [Timeout](#timeout)\n  - [Chai](#chai)\n- [Chaining](#chaining)\n- [Custom Plugins](#custom-plugins)\n- [TypeScript](#typescript)\n\n<!-- tocstop -->\n\nWhy\n===\n\nMocha out of the box often requires a lot of setup and teardown code in `beforeEach/afterEach` filters. Using this library, you can get rid of those entirely and build your tests declaratively by chaining functionality together. Using the builtin plugins and your own, you create bits of functionality and chain them together with a concise syntax. It will greatly reduce the amount of repetition in your codebase.\n\nIt should be compatible with other testing libraries as well (e.g. jest), but may require a couple small changes. If you're interested, try it out and let me know if it works.\n\nAs an example, here is what a test file might look like for an application setup with fancy-test. This chain could partially be stored to a variable for reuse.\n\n```js\ndescribe('api', () => {\n  fancy\n  // [custom plugin] initializes the db\n  .initDB({withUser: mockDBUser})\n\n  // [custom plugin] uses nock to mock out github API\n  .mockGithubAPI({user: mockGithubUser})\n\n  // [custom plugin] that calls the API of the app\n  .call('POST', '/api/user/foo', {id: mockDBUser.id})\n\n  // add adds to the context object\n  // fetch the newly created data from the API (can return a promise)\n  .add('user', ctx => ctx.db.fetchUserAsync(mockDBUser.id))\n\n  // do just runs arbitary code\n  // check to ensure the operation was successful\n  .do(ctx => expect(ctx.user.foo).to.equal('bar'))\n\n  // it is essentially mocha's it(expectation, callback)\n  // start the test and provide a description\n  .it('POST /api/user/foo updates the user')\n})\n```\n\nUsage\n=====\n\nSetup is pretty easy, just install mocha and fancy-test, then you can use any of the examples below.\n\nAssume the following is before all the examples:\n\n```js\nimport {fancy} from 'fancy-test'\nimport {expect} from 'chai'\n```\n\nStub\n----\n\nStub any object. Like all fancy plugins, it ensures that it is reset to normal after the test runs.\n```js\nimport * as os from 'os'\n\ndescribe('stub tests', () => {\n  fancy\n  .stub(os, 'platform', () => 'foobar')\n  .it('sets os', () => {\n    expect(os.platform()).to.equal('foobar')\n  })\n\n  fancy\n  .stub(os, 'platform', sinon.stub().returns('foobar'))\n  .it('uses sinon', () => {\n    expect(os.platform()).to.equal('foobar')\n    expect(os.platform.called).to.equal(true)\n  })\n})\n```\n\nCatch\n-----\n\ncatch errors in a declarative way. By default, ensures they are actually thrown as well.\n\n```js\ndescribe('catch tests', () => {\n  fancy\n  .do(() => { throw new Error('foobar') })\n  .catch(/foo/)\n  .it('uses regex')\n\n  fancy\n  .do(() => { throw new Error('foobar') })\n  .catch('foobar')\n  .it('uses string')\n\n  fancy\n  .do(() => { throw new Error('foobar') })\n  .catch(err => expect(err.message).to.match(/foo/))\n  .it('uses function')\n\n  fancy\n  // this would normally raise because there is no error being thrown\n  .catch('foobar', {raiseIfNotThrown: false})\n  .it('do not error if not thrown')\n})\n```\n\nWithout fancy, you could check an error like this:\n\n```js\nit('dont do this', () => {\n  try {\n    myfunc()\n  } catch (err) {\n    expect(err.message).to.match(/my custom errorr/)\n  }\n})\n```\n\nBut this has a common flaw, if the test does not error, the test will still pass. Chai and other assertion libraries have helpers for this, but they still end up with somewhat messy code.\n\nFinally\n-------\n\nRun a task even if the test errors out.\n\n```js\ndescribe('finally tests', () => {\n  fancy\n  .do(() => { throw new Error('x') })\n  .finally(() => { /* always called */ })\n  .end('always calls finally')\n})\n```\n\nNock\n----\n\nUses [nock](https://github.com/node-nock/nock) to mock out HTTP calls to external APIs. You'll need to also install nock in your `devDependencies`.\nAutomatically calls `done()` to ensure the calls were made and `cleanAll()` to remove any pending requests.\n\n```js\nconst fancy = require('fancy-test')\n\ndescribe('nock tests', () => {\n  fancy\n  .nock('https://api.github.com', api => api\n    .get('/me')\n    .reply(200, {name: 'jdxcode'})\n  )\n  .it('mocks http call to github', async () => {\n    const {body: user} = await HTTP.get('https://api.github.com/me')\n    expect(user).to.have.property('name', 'jdxcode')\n  })\n})\n```\n\nEnvironment Variables\n---------------------\n\nSometimes it's helpful to clear out environment variables before running tests or override them to something common.\n\n```js\ndescribe('env tests', () => {\n  fancy\n  .env({FOO: 'BAR'})\n  .it('mocks FOO', () => {\n    expect(process.env.FOO).to.equal('BAR')\n    expect(process.env).to.not.deep.equal({FOO: 'BAR'})\n  })\n\n  fancy\n  .env({FOO: 'BAR'}, {clear: true})\n  .it('clears all env vars', () => {\n    expect(process.env).to.deep.equal({FOO: 'BAR'})\n  })\n})\n```\n\nDo\n---\n\nRun some arbitrary code within the pipeline. Useful to create custom logic and debugging.\n\n```js\ndescribe('run', () => {\n  fancy\n  .stdout()\n  .do(() => console.log('foo'))\n  .do(({stdout}) => expect(stdout).to.equal('foo\\n'))\n  .it('runs this callback last', () => {\n    // test code\n  })\n\n  // add to context object\n  fancy\n  .add('a', () => 1)\n  .add('b', () => 2)\n  // context will be {a: 1, b: 2}\n  .it('does something with context', context => {\n    // test code\n  })\n})\n```\n\nAdd\n---\n\nSimilar to run, but extends the context object with a new property.\nCan return a promise or not.\n\n```js\ndescribe('add', () => {\n  fancy\n  .add('foo', () => 'foo')\n  .add('bar', () => Promise.resolve('bar'))\n  .do(ctx => expect(ctx).to.include({foo: 'foo', bar: 'bar'}))\n  .it('adds the properties')\n})\n```\n\nStdin Mocking\n-------------\n\nMocks stdin. You may have to pass a delay to have it wait a bit until it sends the event.\n\n```js\ndescribe('stdin test', () => {\n  fancy\n  .stdin('whoa there!\\n')\n  .stdout()\n  .it('mocks', () => {\n    process.stdin.setEncoding('utf8')\n    process.stdin.once('data', data => {\n      // data === 'whoa there!\\n'\n    })\n  })\n})\n```\n\nStdout/Stderr Mocking\n---------------------\n\nThis is used for tests that ensure that certain stdout/stderr messages are made.\nBy default this also trims the output from the screen. See the output by setting `TEST_OUTPUT=1`, or by setting `{print: true}` in the options passed.\n\nYou can use the library [stdout-stderr](https://npm.im/stdout-stderr) directly for doing this, but you have to be careful to always reset it after the tests run. We do that work for you so you don't have to worry about mocha's output being hidden.\n\n```js\ndescribe('stdmock tests', () => {\n  fancy\n  .stdout()\n  .it('mocks stdout', output => {\n    console.log('foobar')\n    expect(output.stdout).to.equal('foobar\\n')\n  })\n\n  fancy\n  .stderr()\n  .it('mocks stderr', output => {\n    console.error('foobar')\n    expect(output.stderr).to.equal('foobar\\n')\n  })\n\n  fancy\n  .stdout()\n  .stderr()\n  .it('mocks stdout and stderr', output => {\n    console.log('foo')\n    console.error('bar')\n    expect(output.stdout).to.equal('foo\\n')\n    expect(output.stderr).to.equal('bar\\n')\n  })\n})\n```\n\nDone\n----\n\nYou can get the mocha `done()` callback by passing in a second argument.\n\n```js\ndescribe('calls done', () => {\n  fancy\n  .it('expects FOO=bar', (_, done) => {\n    done()\n  })\n})\n```\n\nRetries\n-------\n\nRetry the test n times.\n\n```js\nlet count = 3\n\ndescribe('test retries', () => {\n  fancy\n  .retries(2)\n  .do(() => {\n    count--\n    if (count > 0) throw new Error('x')\n  })\n  .it('retries 3 times')\n})\n```\n\nTimeout\n-------\n\nSet mocha timeout duration.\n\n```js\nconst wait = (ms = 10) => new Promise(resolve => setTimeout(resolve, ms))\n\ndescribe('timeout', () => {\n  fancy\n  .timeout(50)\n  .it('times out after 50ms', async () => {\n    await wait(100)\n  })\n})\n```\n\nChai\n----\n\nThis library includes [chai](https://npm.im/chai) for convenience:\n\n```js\nimport {expect, fancy} from 'fancy-test'\n\ndescribe('has chai', () => {\n  fancy\n  .env({FOO: 'BAR'})\n  .it('expects FOO=bar', () => {\n    expect(process.env.FOO).to.equal('BAR')\n  })\n})\n```\n\nChaining\n========\n\nEverything here is chainable. You can also store parts of a chain to re-use later on.\n\nFor example:\n\n```js\ndescribe('my suite', () => {\n  let setupDB = fancy\n                .do(() => setupDB())\n                .env({FOO: 'FOO'})\n\n  setupDB\n  .stdout()\n  .it('tests with stdout mocked', () => {\n    // test code\n  })\n\n  setupDB\n  .env({BAR: 'BAR'})\n  .it('also mocks the BAR environment variable', () => {\n    // test code\n  })\n})\n```\n\nUsing [do](#do) you can really maximize this ability. In fact, you don't even need to pass a callback to it if you prefer this syntax:\n\n```js\ndescribe('my suite', () => {\n  let setupDB = fancy\n                .do(() => setupDB())\n                .catch(/spurious db error/)\n                .do(() => setupDeps())\n\n  let testMyApp = testInfo => {\n    return setupDB.run()\n    .do(context => myApp(testInfo, context))\n  }\n\n  testMyApp({info: 'test run a'})\n  .it('tests a')\n\n  testMyApp({info: 'test run b'})\n  .it('tests b')\n})\n```\n\nCustom Plugins\n==============\n\nIt's easy to create your own plugins to extend fancy. In [oclif](https://github.com/oclif/oclif) we use fancy to create [custom command testers](https://github.com/oclif/example-multi-ts/blob/main/test/commands/hello.test.ts).\n\nHere is an example that creates a counter that could be used to label each test run. See the [actual test](test/base.test.ts) to see the TypeScript types needed.\n\n```js\nlet count = 0\n\nfancy = fancy\n.register('count', prefix => {\n  return {\n    run(ctx) {\n      ctx.count = ++count\n      ctx.testLabel = `${prefix}${count}`\n    }\n  }\n})\n\ndescribe('register', () => {\n  fancy\n  .count('test-')\n  .it('is test #1', context => {\n    expect(context.count).to.equal(1)\n    expect(context.testLabel).to.equal('test-1')\n  })\n\n  fancy\n  .count('test-')\n  .it('is test #2', context => {\n    expect(context.count).to.equal(2)\n    expect(context.testLabel).to.equal('test-2')\n  })\n})\n```\n\nTypeScript\n==========\n\nThis module is built in typescript and exports the typings. Doing something with dynamic chaining like this was [not easy](src/base.ts), but it should be fully typed throughout. Look at the internal plugins to get an idea of how to keep typings for your custom plugins.\n"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.yarnpkg.com/fancy-test/-/fancy-test-2.0.37.tgz#7cfd18fcaaa76cd2d72636dda00f6f3fae053187",
    "type": "tarball",
    "reference": "https://registry.yarnpkg.com/fancy-test/-/fancy-test-2.0.37.tgz",
    "hash": "7cfd18fcaaa76cd2d72636dda00f6f3fae053187",
    "integrity": "sha512-lCicyu0gzcWNR0x5LyRNGjBNJfrl+C9rKOaC6nJcyPUXvMhZkMVwsCIDuMPaEET0sD8vSliyAipnQ7RZUgXujw==",
    "registry": "npm",
    "packageName": "fancy-test",
    "cacheIntegrity": "sha512-lCicyu0gzcWNR0x5LyRNGjBNJfrl+C9rKOaC6nJcyPUXvMhZkMVwsCIDuMPaEET0sD8vSliyAipnQ7RZUgXujw== sha1-fP0Y/KqnbNLXJjbdoA9vP64FMYc="
  },
  "registry": "npm",
  "hash": "7cfd18fcaaa76cd2d72636dda00f6f3fae053187"
}